{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, num_in, num_hidden, num_out, learning_rate, activation = 'sigmoid'):\n",
    "        self.lr = learning_rate\n",
    "        #num output nodes\n",
    "        self.num_out = num_out\n",
    "        #list that maintains layers\n",
    "        self.layers = []\n",
    "        np.random.seed(40)\n",
    "        #randomly generate starting weights\n",
    "        hidden = [{\"weights\": [np.random.random() for j in range(num_in + 1)], \"activation\": \"sigmoid\"} for i in range(num_hidden)]\n",
    "        out = [{\"weights\": [np.random.random() for j in range(num_hidden + 1)], \"activation\": activation} for i in range(num_out)]\n",
    "        self.layers.append(hidden)\n",
    "        self.layers.append(out)\n",
    "    \n",
    "    #Relu activation, accepts inputs and applies relu function to each\n",
    "    def relu_activation(self, inputs):\n",
    "        return [max(0.0, val) for val in inputs]\n",
    "        \n",
    "    #Sigmoid activation + transfer. was running into issues with exp overflow when I didn't combine\n",
    "    #these steps into a single method and attempted to separate into sigmoid activation followed by multiplying\n",
    "    #by weights\n",
    "    def sigmoid_activation(self, weights, inputs):\n",
    "        lin_sum = weights[-1] #bias\n",
    "        for i in range(len(inputs)):\n",
    "            lin_sum += inputs[i]*weights[i]\n",
    "        return 1.0/(1.0 + np.exp(-lin_sum))\n",
    "    \n",
    "    #applies derivative of sigmoid function to some values\n",
    "    def derivative_sigmoid(self, sig):\n",
    "        return sig * (1 - sig)\n",
    "    \n",
    "    #applies derivative of relu function to some values\n",
    "    def derivative_relu(self, inputs):\n",
    "        return [1 if x > 0 else 0 for x in inputs]\n",
    "    \n",
    "    #forward propogate to make predictions by updating the 'out' field of each neuron\n",
    "    def forward(self, input_vector):\n",
    "        for layer in self.layers:\n",
    "            out = []\n",
    "            for neuron in layer:\n",
    "                #apply sigmoid activation and weights to make neuron's prediction\n",
    "                if neuron['activation'] == 'sigmoid':\n",
    "                    neuron['out'] = self.sigmoid_activation(neuron['weights'], input_vector)\n",
    "                #apply relu activation and weights to make prediction\n",
    "                else:\n",
    "                    activated = self.relu_activation(input_vector)\n",
    "                    neuron['out'] = sum([neuron['weights'][i] * activated[i] for i in range(len(activated))])\n",
    "                out.append(neuron['out'])\n",
    "            #represents the input into the next layer, which is a list of all the current layer's neurons' outputs\n",
    "            input_vector = out\n",
    "        #return the predictions for the last layer\n",
    "        return input_vector\n",
    "    \n",
    "    #back propogate to train the NN on the data\n",
    "    def back_propogate(self, expected):\n",
    "        #move backwards, starting from the last layer to the first\n",
    "        for i in range(len(self.layers) - 1, -1, -1):\n",
    "            layer = self.layers[i]\n",
    "            #the errors on each neuron\n",
    "            errors = []\n",
    "            if i != len(self.layers) - 1: #bias term\n",
    "                for j in range(len(layer)):\n",
    "                    error_sum = 0\n",
    "                    for neuron in self.layers[i+1]:\n",
    "                        error_sum += neuron['weights'][j] * neuron['delta']\n",
    "                    errors.append(error_sum)\n",
    "            else:\n",
    "                for j in range(len(layer)):\n",
    "                    errors.append(expected[j] - layer[j]['out'])\n",
    "            #use the error times the derivative of the activation function to move towards the weights that minimmize\n",
    "            #the error\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                if neuron['activation'] == 'sigmoid':\n",
    "                    neuron['delta'] = errors[j] * self.derivative_sigmoid(neuron['out'])\n",
    "                else:\n",
    "                    neuron['delta'] = errors[j] * sum(self.derivative_relu(neuron['out']))\n",
    "    \n",
    "    #update the weights of each node\n",
    "    def update_w(self, row):\n",
    "        for i in range(len(self.layers)):\n",
    "            layer_input = row[:-1]\n",
    "            #no error on the first layer (input layer)\n",
    "            if i != 0:\n",
    "                layer_input = [neuron['out'] for neuron in self.layers[i-1]]\n",
    "            #use learning rate times the previously calculated delta value times the input into the layer\n",
    "            #to step towards zero-loss weights in the delta direction with step size tuned by learning reight\n",
    "            for neuron in self.layers[i]:\n",
    "                for j in range(len(layer_input)):\n",
    "                    neuron['weights'][j] += self.lr * neuron['delta'] * layer_input[j]\n",
    "            #bias term\n",
    "            neuron['weights'][-1] += self.lr * neuron['delta']\n",
    "    \n",
    "    #train on data\n",
    "    def train(self, train_data, test_data, max_epochs = 1000):\n",
    "        self.graph(max_epochs)\n",
    "        #update over epochs\n",
    "        for epoch in range(max_epochs):\n",
    "            train_epoch_error = 0\n",
    "            test_epoch_error = 0\n",
    "            \n",
    "            #training data\n",
    "            for row in train_data:\n",
    "                #make predictions using current model\n",
    "                epoch_out = self.forward(row)\n",
    "                \n",
    "                #get error of those predictions\n",
    "                expected_out_prob = [0 for i in range(self.num_out)]\n",
    "                expected_out_prob[int(row[-1])] = 1\n",
    "                train_epoch_error += sum([(expected_out_prob[i] - epoch_out[i])**2 for i in range(len(expected_out_prob))])\n",
    "                \n",
    "                #update the weights based on those calculated errors\n",
    "                self.back_propogate(expected_out_prob)\n",
    "                self.update_w(row)   \n",
    "            \n",
    "            #plot error of this epoch\n",
    "            plt.plot(epoch, train_epoch_error/len(train_data), 'ro', label = \"training\")\n",
    "            \n",
    "            #test data\n",
    "            for row in test_data:\n",
    "                #make prediction based on current model\n",
    "                predicted = self.predict(row)\n",
    "                test_epoch_error += (predicted - row[-1]) ** 2\n",
    "                \n",
    "            #plot performance on test data\n",
    "            plt.plot(epoch, test_epoch_error/len(test_data), 'bo', label = \"test\")\n",
    "    \n",
    "    #predict label of given row of data\n",
    "    def predict(self, row):\n",
    "        out_probs = self.forward(row)\n",
    "        max_prob = float('-inf')\n",
    "        max_ind = -1\n",
    "        for i in range(len(out_probs)):\n",
    "            if out_probs[i] > max_prob:\n",
    "                max_ind = i\n",
    "                max_prob = out_probs[i]\n",
    "        return max_ind\n",
    "    \n",
    "    #set up the graph\n",
    "    def graph(self, max_epochs):\n",
    "        plt.xlim(0, max_epochs)\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"least squares error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.genfromtxt('iris.data', delimiter=',', dtype = None, encoding = None)\n",
    "num_label_data = []\n",
    "\n",
    "iris_dict = {\n",
    "    \"Iris-setosa\": 0,\n",
    "    \"Iris-versicolor\": 1,\n",
    "    \"Iris-virginica\": 2\n",
    "}\n",
    "\n",
    "for row in raw_data:\n",
    "    sep_len, sep_width, pet_len, pet_width, label = row\n",
    "    label = iris_dict[label]\n",
    "    #using the max of each attribute (provided in iris.names on the dataset) to normalize\n",
    "    sep_len /= 7.6\n",
    "    sep_width /= 4.4\n",
    "    pet_len /= 6.9\n",
    "    pet_width /= 2.5\n",
    "    num_label_data.append((sep_len, sep_width, pet_len, pet_width, int(label)))\n",
    "\n",
    "np.random.shuffle(num_label_data)\n",
    "\n",
    "train_test_spl = int(len(raw_data) * 0.85)\n",
    "train = np.array(num_label_data[:train_test_spl])\n",
    "test = np.array(num_label_data[train_test_spl:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = NeuralNetwork(4, 20, 3, 0.2, activation = 'sigmoid')\n",
    "net.train(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
